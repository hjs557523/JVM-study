一、高性能硬件上的程序部署策略
 在高性能硬件上部署程序，目前主要有两种方式：
（1）通过64位JDK来使用大内存
     存在问题：
     1、内存回收导致的长时间停顿
     2、现阶段，64位JDK的性能测试结果普遍低于32位JDK
     3、需要保证程序足够稳定，因为这种应用要是产生堆溢出几乎就无法产生堆转储快照（因为要产生十几GB乃至更大的Dump文件），哪怕产生了快照也几乎无法进行分析。
     4、相同程序在64位JDK消耗的内存一般比32位JDK大，这是由于指针膨胀，以及数据类型对齐补白等因素导致的。

（2）使用若干个32位虚拟机建立逻辑集群来利用硬件资源
     目前大多都采用这种方式。
     具体做法是：在一台物理机器上启动多个应用服务器进程，每个服务器进程分配不同端口，然后在前端搭建一个负载均衡器，以反向代理的方式来分配访问请求。
     
     亲合式集群：
     考虑到在一台物理机器上建立逻辑集群的目的仅仅是为了尽可能利用硬件资源，并不需要关心状态保留、热转移之类的高可用性需求，也不需要保证每个虚拟机进程有绝对准确的均衡负载，
     因此使用无Session复制的亲合式集群是一个相当不错的选择。我们仅仅需要保障集群具备亲合性，也就是均衡器按一定的规则算法（一般根据SessionID分配）将一个固定的用户请求永远
     分配到固定的一个集群节点进行处理即可，这样程序开发阶段就基本不用为集群环境做什么特别的考虑了。

     逻辑集群：
     1、尽量避免节点竞争全局资源，最典型的就是磁盘竞争，如果各个节点同时访问某个磁盘文件（并发写操作），很容易导致IO异常
     2、很难最高效率地利用某些资源池（如连接池，一般都是在各个节点建立自己独立的连接池，这样有可能导致一些节点池满了而另外一些节点仍有较多空余。尽管可以使用集中式JNDI，但
        这个有一定复杂性并且可能带来额外的性能开销）。
     3、各个节点仍然不可避免地受到32位的内存限制，在32位Windows平台中每个进程只能使用2GB的内存，考虑到堆以外的内存开销，堆一般最多只能开到1.5GB。在某些Linux或UNIX系统中，
        可以提升到3GB乃至4GB的内存，但32位中仍然受到最高4GB(2^32)内存的限制。
     4、大量使用本地缓存（如大量使用HashMap作为K/V缓存）的应用，在逻辑集群中会造成较大的内存浪费，因为每个逻辑节点上都有一份缓存，这时候可以考虑把本地缓存改为集中式缓存。


二、集群间同步导致的内存溢出
    JBossCache 

三、堆外内存导致的溢出错误 
    永久代、Direct Memory、线程堆栈、Socket缓存区、JNI代码、虚拟机、GC

四、外部命令导致系统缓慢  
    Runtime.getRuntime().exec() ----> fork()

五、服务器JVM进程崩溃


六、不恰当数据结构导致内存占用过大
    HashMap<Long,Long>结构存储数据文件空间效率太低
    Key    8B -> 包装成java.lang.Long对象 = 8B 有效数据 + 8B MarkWord + 8B Klass指针 = 24B 
    Value  8B -> 包装成java.lang.Long对象 = 8B 有效数据 + 8B MarkWord + 8B Klass指针 = 24B
    两个Long对象组成Map.Entry = 24B Long对象 * 2 + 16B 对象头 + 8B next字段 + 4B int型hashcode + 4B 空白对齐填充 + 8B HasnMap Ref = 88B   
 

七、由Windows虚拟内存导致的长时间停顿

八、实战
   当JDK如果未使用 -XX:MaxPermSize参数明确指定永久代最大容量时的默认值，则无论JDK1.5还是JDK1.6，这个默认值都是64MB
   新生代GC频繁发生，很可能是由于虚拟机分配给新生代的空间太小而导致的 -Xmn
   老年代GC时间过长，很可能是由于每一次 Full GC 老年代和永久代内存扩展所致 -Xmx、-Xms、-XX:PermSize=、-XX:MaxPermSize=